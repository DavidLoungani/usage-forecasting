{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T12:47:42.049975Z",
     "start_time": "2017-06-21T12:47:35.663597Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "''' Database querying '''\n",
    "\n",
    "\n",
    "def getDatabaseConnection():\n",
    "    import os\n",
    "    import yaml\n",
    "    from sqlalchemy import create_engine\n",
    "    db_conn = os.path.join(os.getcwd(), \"db_connections/db_connections.yml\")\n",
    "    with open(db_conn, 'r') as ymlfile:\n",
    "        db_conns = yaml.load(ymlfile)\n",
    "    redshift = db_conns['Redshift']\n",
    "    # megavolt = db_conns['Megavolt']\n",
    "    engine = 'postgresql://{username}:{password}@{host}:{port}/{database}'.format(username=redshift['username'],\n",
    "                                                                                  password=redshift['password'],\n",
    "                                                                                  host=redshift['host'],\n",
    "                                                                                  port=redshift['port'],\n",
    "                                                                                  database=redshift['database'])\n",
    "    conn = create_engine(engine, connect_args={'sslmode': 'require'})\n",
    "    return conn\n",
    "\n",
    "\n",
    "def queryDatabase():\n",
    "    def queryInvoiceData(conn):\n",
    "        p1 = \"with cte as (select a.iethicalid, a.cesuniqueid, a.szip, it.* from ee.accounts a join ee.v_invoicestemp it on it.uniqueaccountid = a.cesuniqueid)\"\n",
    "        p2 = \"select distinct iethicalid, szip, invoicefromdt, invoicetodt, kwh from cte order by iethicalid\"\n",
    "        q = p1 + p2\n",
    "        df = pd.read_sql_query(q, con=conn)\n",
    "        return df\n",
    "\n",
    "    conn = getDatabaseConnection()\n",
    "    invoice_dataframe = queryInvoiceData(conn)\n",
    "    closest_stations_dataframe = pd.read_sql_query(\"select * from public.weather_stations where ord=1;\", con=conn)\n",
    "    weather_data = pd.read_sql_query(\"select wban, yearmonthday, tavg from consumption.noaa_data\", con=conn)\n",
    "    merged_invoice_df = pd.merge(invoice_dataframe, closest_stations_dataframe, left_on='szip', right_on='zip')\n",
    "    merged_invoice_df['invoicefromdt'] = pd.to_datetime(merged_invoice_df['invoicefromdt'])\n",
    "    merged_invoice_df['invoicetodt'] = pd.to_datetime(merged_invoice_df['invoicetodt'])\n",
    "    cust_database = CustomerDatabase(merged_invoice_df, weather_data)\n",
    "    return cust_database\n",
    "\n",
    "\n",
    "''' Utility functions '''\n",
    "\n",
    "\n",
    "def shaveData(dataframe, col, final_time):\n",
    "    # Shave off time intervals after specified final time\n",
    "    found = False\n",
    "    final_time_idx = len(dataframe.index)\n",
    "    for idx in dataframe.index:\n",
    "        if (dataframe[col][idx] > final_time) and not found:\n",
    "            final_time_idx = idx\n",
    "            found = True\n",
    "    return dataframe[0:final_time_idx]\n",
    "\n",
    "\n",
    "def addTemporalValues(dataframe):\n",
    "    # split timestamp into year, month, and day values, for regression\n",
    "    dataframe['year'] = list(map(lambda x: x.year, dataframe['invoicetodt']))\n",
    "    dataframe['month'] = list(map(lambda x: x.month, dataframe['invoicetodt']))\n",
    "    dataframe['day'] = list(map(lambda x: x.day, dataframe['invoicetodt']))\n",
    "\n",
    "    # Add a \"days passed\" column and iterate over dataframe to complete it'\n",
    "    dataframe['days_passed'] = list(map(lambda x: (x - dataframe['invoicetodt'][0]).days, dataframe['invoicetodt']))\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def massage(data):\n",
    "    # massage the data to make pandas happy\n",
    "    length = len(data)\n",
    "    data = np.asmatrix(data)\n",
    "    data = data.reshape(length, 1)\n",
    "    return data\n",
    "\n",
    "\n",
    "def copyCustomer(customer):\n",
    "    c = Customer(customer.id, customer.data.copy())\n",
    "    c.createEval()\n",
    "    return c\n",
    "\n",
    "\n",
    "# TODO: Not sure if this actually works!!! Is there a better way to do this?\n",
    "def createFactors(a, b):\n",
    "    final = (a[a.columns[0]] * b[b.columns[0]]).as_matrix()\n",
    "    final = final.reshape(len(final), 1)\n",
    "    i = 0\n",
    "    j = 1\n",
    "    while i < len(a.columns):\n",
    "        while j < len(b.columns):\n",
    "            temp = (a[a.columns[i]] * b[b.columns[j]])\n",
    "            temp = temp.reshape(len(temp), 1)\n",
    "            final = np.hstack((final, temp))\n",
    "            j += 1\n",
    "        j = 0\n",
    "        i += 1\n",
    "    return final\n",
    "\n",
    "\n",
    "\n",
    "''' Classes '''\n",
    "\n",
    "\n",
    "def merge(slice_1, slice_2):\n",
    "    slice_1.listSufficient.extend(slice_2.listSufficient)\n",
    "    slice_1.listInsufficient.extend(slice_2.listInsufficient)\n",
    "    merged_slice = CustomerSlice(slice_1.listSufficient, slice_1.listInsufficient)\n",
    "    return merged_slice\n",
    "\n",
    "\n",
    "class CustomerDatabase:\n",
    "    def __init__(self, invoice_df, weather_df):\n",
    "        self.invoice_df = invoice_df\n",
    "        self.weather_df = weather_df\n",
    "\n",
    "    def getSpecificCustomerDataframe(self, selected_id: str) -> pd.DataFrame:\n",
    "        # Internal methods\n",
    "        def calculatePeriod(fromdt, todt):\n",
    "            return pd.period_range(fromdt, todt, freq='D')\n",
    "\n",
    "        def cleanVals(x):\n",
    "            if x is 'M':\n",
    "                x = None\n",
    "            else:\n",
    "                x = pd.to_numeric(x, errors='coerce')\n",
    "            return x\n",
    "\n",
    "        customer_usage_df = ((self.invoice_df.loc[self.invoice_df['iethicalid'] == selected_id]).sort_values(\n",
    "            by='invoicefromdt')).reset_index()\n",
    "        # Shave off unnecessary values (unnecessary, for now!)\n",
    "        customer_usage_df_final = customer_usage_df[['invoicetodt', 'kwh']].copy()\n",
    "        # check to make sure weather station does not change\n",
    "        if (customer_usage_df['wban'].nunique()) == 1:\n",
    "            weather_station = int(customer_usage_df['wban'][0])\n",
    "        else:\n",
    "            raise ValueError('Customer changes weather stations')\n",
    "\n",
    "        # Convert all values from strings to numerics, and change M's to NaNs\n",
    "        weather_df_slice = self.weather_df[self.weather_df['wban'] == weather_station]\n",
    "        weather_df_slice['tavg'] = list(map(cleanVals, weather_df_slice['tavg']))\n",
    "\n",
    "        for interval_idx in customer_usage_df_final.index:\n",
    "            days = calculatePeriod(customer_usage_df['invoicefromdt'][interval_idx],\n",
    "                                   customer_usage_df['invoicetodt'][interval_idx])\n",
    "            plotframe = pd.DataFrame(days, columns=['day'])\n",
    "\n",
    "            def to_dateQuery(date):\n",
    "                temp_string = str(date.year)\n",
    "                if date.month < 10:\n",
    "                    temp_string += \"0\"\n",
    "                temp_string += str(date.month)\n",
    "\n",
    "                if date.day < 10:\n",
    "                    temp_string += \"0\"\n",
    "                temp_string += str(date.day)\n",
    "                return int(temp_string)\n",
    "\n",
    "            plotframe['dateQuery'] = list(map(to_dateQuery, plotframe['day']))\n",
    "\n",
    "            combined_usage_data = pd.merge(plotframe, weather_df_slice, left_on='dateQuery', right_on='yearmonthday')\n",
    "            interval_temp_sum = np.sum(combined_usage_data['tavg'])\n",
    "\n",
    "            # Last robustness check - otherwise set the tavg interval sum\n",
    "            if interval_temp_sum == 0:\n",
    "                customer_usage_df_final.loc[[interval_idx], 'tavg_intervalSum'] = None\n",
    "            else:\n",
    "                customer_usage_df_final.loc[[interval_idx], 'tavg_intervalSum'] = interval_temp_sum\n",
    "\n",
    "        return customer_usage_df_final\n",
    "\n",
    "    def getSpecificCustomer(self, selected_id):\n",
    "        customer_usage_df = self.getSpecificCustomerDataframe(selected_id)\n",
    "\n",
    "        # drop NA's\n",
    "        if customer_usage_df.isnull().values.any():\n",
    "            customer_usage_df = customer_usage_df.dropna()\n",
    "\n",
    "        length = len(customer_usage_df)\n",
    "        if length < 5:\n",
    "            raise ValueError('insufficient data on customer: ID' + str(selected_id))\n",
    "\n",
    "        customer = Customer(selected_id, customer_usage_df)\n",
    "        return customer\n",
    "\n",
    "    def selectSliceByIDs(self, id_list):\n",
    "        print('Selecting slice by IDs...')\n",
    "        num_processed_customers = 0\n",
    "        num_discarded_customers = 0\n",
    "        num_customers = len(id_list)\n",
    "\n",
    "        list_sufficient = []\n",
    "        list_insufficient = []\n",
    "\n",
    "        for uniqueID in id_list:\n",
    "            percent = ((num_processed_customers + num_discarded_customers) / num_customers) * 100\n",
    "            print('Percent completed:  ' + str(percent) + '%')\n",
    "            try:\n",
    "                customer = self.getSpecificCustomer(uniqueID)\n",
    "                customer.formatData()\n",
    "                print('Customer selected: ' + str(uniqueID))\n",
    "                list_sufficient.append(customer)\n",
    "                num_processed_customers += 1\n",
    "            except ValueError:\n",
    "                print(\"Customer discarded, insufficient data: \" + str(uniqueID))\n",
    "                list_insufficient.append(uniqueID)\n",
    "                num_discarded_customers += 1\n",
    "\n",
    "        print('selectSliceByIDs terminated successfully')\n",
    "        print('Processed customers: ' + str(num_processed_customers))\n",
    "        print('Discarded customers: ' + str(num_discarded_customers))\n",
    "\n",
    "        cust_slice = CustomerSlice(list_sufficient, list_insufficient)\n",
    "        return cust_slice\n",
    "\n",
    "    def selectAllCustomers(self):\n",
    "        id_list = self.invoice_df['iethicalid'].unique()\n",
    "        cust_slice = self.selectSliceByIDs(id_list)\n",
    "        return cust_slice\n",
    "\n",
    "    def selectRandomSlice(self, cust_count):\n",
    "        from random import shuffle\n",
    "        id_list = self.invoice_df['iethicalid'].unique().copy()\n",
    "\n",
    "        if cust_count > len(id_list):\n",
    "            raise ValueError('Cannot request more customers than exists in database')\n",
    "\n",
    "        shuffle(id_list)\n",
    "        id_list = id_list[0:cust_count]\n",
    "        cust_slice = self.selectSliceByIDs(id_list)\n",
    "        return cust_slice\n",
    "\n",
    "    # TODO: Problem, this leaves the possibility of non-unique customers being merged\n",
    "    def selectRandomHardSlice(self, cust_count):\n",
    "        cust_slice = self.selectRandomSlice(cust_count)\n",
    "        num_processed = len(cust_slice.listSufficient)\n",
    "        while num_processed < cust_count:\n",
    "            cust_slice = merge(cust_slice, self.selectRandomSlice(cust_count - num_processed))\n",
    "            num_processed = len(cust_slice.listSufficient)\n",
    "        return cust_slice\n",
    "\n",
    "\n",
    "class CustomerSlice:\n",
    "    def __init__(self, list_sufficient, list_insufficient):\n",
    "        self.listSufficient = list_sufficient\n",
    "        self.listInsufficient = list_insufficient\n",
    "        self.iter = 0\n",
    "        columns = ['regression approach', 'RMSQE', 'AE', 'MAE']\n",
    "        self.grand_errorFrame = pd.DataFrame(columns=columns)\n",
    "\n",
    "    def get_ID_list(self):\n",
    "        id_list = []\n",
    "        for customer in self.listSufficient:\n",
    "            id_list.append(customer.id)\n",
    "        return id_list\n",
    "\n",
    "    def copy(self):\n",
    "        new_slice = CustomerSlice(list(map(copyCustomer, self.listSufficient)), self.listInsufficient)\n",
    "        return new_slice\n",
    "\n",
    "    def reset_grand_errorFrame(self, algorithms):\n",
    "        for idx in algorithms.index:\n",
    "            self.grand_errorFrame.loc[idx] = ['predicted_kwh_' + str(algorithms['name'][idx]), 0, 0, 0]\n",
    "        for idx in self.grand_errorFrame.index:\n",
    "            self.grand_errorFrame.loc[[idx], 'AE'] = 0\n",
    "            self.grand_errorFrame.loc[[idx], 'MAE'] = 0\n",
    "\n",
    "    def runModels(self, train_columns, categorical_columns, target_column, algorithms):\n",
    "        num_customers = len(self.listSufficient)\n",
    "        count = 0\n",
    "        self.reset_grand_errorFrame(algorithms)\n",
    "        # TODO: VECTORIZE THE FOR LOOPS ?\n",
    "        for customer in self.listSufficient:\n",
    "            customer.runModels(train_columns, categorical_columns, target_column, algorithms)\n",
    "            for idx in algorithms.index:\n",
    "                self.grand_errorFrame.loc[[idx], 'AE'] += \\\n",
    "                    int(customer.errorFrame[customer.errorFrame['regression approach']\n",
    "                                            == 'predicted_kwh_' + str(algorithms['name'][idx])]['AE'])\n",
    "                self.grand_errorFrame.loc[[idx], 'MAE'] += \\\n",
    "                    int(customer.errorFrame[customer.errorFrame['regression approach']\n",
    "                                            == 'predicted_kwh_' + str(algorithms['name'][idx])]['MAE'])\n",
    "            count += 1\n",
    "            percent = (count / num_customers) * 100\n",
    "            print('Percent completed:  ' + str(percent) + '%')\n",
    "\n",
    "        for idx in algorithms.index:\n",
    "            self.grand_errorFrame.loc[[idx], 'MAE'] = self.grand_errorFrame['MAE'][idx] / len(self.listSufficient)\n",
    "\n",
    "    def getSummaryStats(self, column):\n",
    "        num_customers = len(self.listSufficient)\n",
    "        count = 0\n",
    "\n",
    "        # average\n",
    "        sum = 0\n",
    "        for customer in self.listSufficient:\n",
    "            sum += customer.data[column].mean()\n",
    "            count += 1\n",
    "        avg = sum / count\n",
    "        return avg\n",
    "\n",
    "    def displayErrors(self):\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        y_pos = np.arange(len(self.grand_errorFrame['regression approach']))\n",
    "        plt.bar(y_pos, self.grand_errorFrame['AE'])\n",
    "        plt.xticks(y_pos, self.grand_errorFrame['regression approach'])\n",
    "        plt.legend(loc='best')\n",
    "        plt.title('Aggregate errors in slice')\n",
    "        plt.show()\n",
    "\n",
    "    def resetIter(self):\n",
    "        self.iter = 0\n",
    "\n",
    "    def iterNext(self):\n",
    "        if self.iter + 1 < len(self.listSufficient):\n",
    "            self.iter += 1\n",
    "        else:\n",
    "            print('Resetting iter, reached end of list')\n",
    "            self.resetIter()\n",
    "\n",
    "    def displayAndNext(self, algorithms):\n",
    "        self.listSufficient[self.iter].displayConclusions(algorithms)\n",
    "        self.iterNext()\n",
    "\n",
    "    def classificationTest(self):\n",
    "        df = pd.DataFrame(columns=['customer', 'id', 'class'])\n",
    "        df['customer'] = self.listSufficient\n",
    "        for idx in df.index:\n",
    "            df['id'][idx] = df['customer'][idx].id\n",
    "            t_at_high = df['customer'][idx].getValueAtMax('kwh', 'tavg_intervalSum')\n",
    "            t_at_low = df['customer'][idx].getValueAtMin('kwh', 'tavg_intervalSum')\n",
    "            if t_at_high > t_at_low:\n",
    "                df['class'][idx] = \"summer peaker\"\n",
    "            elif t_at_high < t_at_low:\n",
    "                df['class'][idx] = \"winter peaker\"\n",
    "            else:\n",
    "                df['class'][idx] = \"pattern unclear\"\n",
    "        return df\n",
    "\n",
    "    def createAggregateFrame(self):\n",
    "        count = 1\n",
    "        aggFrame = self.listSufficient[0].non_eval\n",
    "        while (count < len(self.listSufficient)):\n",
    "            aggFrame = aggFrame.append(self.listSufficient[count].non_eval)\n",
    "            count = count + 1\n",
    "        self.aggFrame = aggFrame.sort_values(by='invoicetodt').reset_index().drop('index', 1)\n",
    "\n",
    "    def createTestFrame(self, algorithms):\n",
    "        count = 1\n",
    "        testFrame = self.listSufficient[0].eval\n",
    "        while (count < len(self.listSufficient)):\n",
    "            testFrame = testFrame.append(self.listSufficient[count].eval)\n",
    "            count = count + 1\n",
    "        self.allFrame = pd.concat([self.aggFrame, testFrame])\n",
    "        self.testFrame = testFrame.reset_index()\n",
    "        for idx in algorithms.index:\n",
    "            self.testFrame['predicted_kwh_' + str(algorithms['name'][idx])] = None\n",
    "\n",
    "    def create_aggregate_ErrorFrame(self, algorithms):\n",
    "        columns = ['regression approach', 'RMSQE', 'AE', 'MAE']\n",
    "        self.agg_errorFrame = pd.DataFrame(columns=columns)\n",
    "        for idx in algorithms.index:\n",
    "            self.agg_errorFrame.loc[idx] = ['predicted_kwh_' + str(algorithms['name'][idx]), 0, 0, 0]\n",
    "\n",
    "    def createTrainSets(self, train_columns, categorical_columns, interaction_columns, target_column):\n",
    "        train_X = self.aggFrame.as_matrix(columns=train_columns)\n",
    "        # TODO: Vectorize and Abstract? Right now categorical/interactions are a mess...\n",
    "        for column in categorical_columns:\n",
    "            cat_col = pd.Categorical(self.aggFrame[column])\n",
    "            mx_dummies = pd.get_dummies(cat_col)\n",
    "            train_X = np.hstack((train_X, mx_dummies))\n",
    "        # TODO: The interaction variable creation here is disgustingly messy\n",
    "        for entry in interaction_columns:\n",
    "            if (entry[2]=='categorical'):\n",
    "                cat_col = pd.Categorical(self.aggFrame[entry[0]])\n",
    "                mx_dummies = pd.get_dummies(cat_col)\n",
    "                a = mx_dummies\n",
    "            else:\n",
    "                mx = self.aggFrame.as_matrix(columns=[entry[0]])\n",
    "                a = pd.DataFrame(mx, columns=['numerical'])\n",
    "            if (entry[3]=='categorical'):\n",
    "                cat_col = pd.Categorical(self.aggFrame[entry[1]])\n",
    "                mx_dummies = pd.get_dummies(cat_col)\n",
    "                b = mx_dummies\n",
    "            else:\n",
    "                mx = self.aggFrame.as_matrix(columns=[entry[1]])\n",
    "                b = pd.DataFrame(mx, columns=['numerical'])\n",
    "            interaction_data = createFactors(a, b)\n",
    "            train_X = np.hstack((train_X, interaction_data))\n",
    "        train_y = self.aggFrame.as_matrix(columns=[target_column])\n",
    "        return train_X, train_y\n",
    "\n",
    "    def createTestSets(self, train_columns, categorical_columns, interaction_columns, target_column):\n",
    "        test_X = self.testFrame.as_matrix(columns=train_columns)\n",
    "        # TODO: Vectorize\n",
    "        for column in categorical_columns:\n",
    "            cat_col = pd.Categorical(self.testFrame[column])\n",
    "            mx_dummies = pd.get_dummies(cat_col)\n",
    "            test_X = np.hstack((test_X, mx_dummies))\n",
    "        # TODO: The interaction variable creation here is disgustingly messy\n",
    "        for entry in interaction_columns:\n",
    "            if (entry[2] == 'categorical'):\n",
    "                cat_col = pd.Categorical(self.testFrame[entry[0]])\n",
    "                mx_dummies = pd.get_dummies(cat_col)\n",
    "                a = mx_dummies\n",
    "            else:\n",
    "                mx = self.testFrame.as_matrix(columns=[entry[0]])\n",
    "                a = pd.DataFrame(mx, columns=['numerical'])\n",
    "            if (entry[3] == 'categorical'):\n",
    "                cat_col = pd.Categorical(self.testFrame[entry[1]])\n",
    "                mx_dummies = pd.get_dummies(cat_col)\n",
    "                b = mx_dummies\n",
    "            else:\n",
    "                mx = self.testFrame.as_matrix(columns=[entry[1]])\n",
    "                b = pd.DataFrame(mx, columns=['numerical'])\n",
    "            interaction_data = createFactors(a, b)\n",
    "            test_X = np.hstack((test_X, interaction_data))\n",
    "        test_y = self.testFrame.as_matrix(columns=[target_column])\n",
    "        return test_X, test_y\n",
    "\n",
    "    def run_aggregate_models(self, train_columns, categorical_columns, interaction_columns, target_column, algorithms):\n",
    "        self.createAggregateFrame()\n",
    "        self.createTestFrame(algorithms)\n",
    "        self.create_aggregate_ErrorFrame(algorithms)\n",
    "\n",
    "        train_X, train_y = self.createTrainSets(train_columns, categorical_columns, interaction_columns, target_column)\n",
    "        target_X, target_y = self.createTestSets(train_columns, categorical_columns, interaction_columns, target_column)\n",
    "\n",
    "        algorithms['fitted_model'] = algorithms['algorithm']\n",
    "        # TODO: Vectorize\n",
    "        for idx in algorithms.index:\n",
    "            current_algo =  algorithms['algorithm'][idx]\n",
    "            algorithms['fitted_model'][idx] = current_algo.fit(train_X, train_y)\n",
    "            for cust_idx in self.testFrame.index:\n",
    "                self.testFrame['predicted_kwh_' + str(algorithms['name'][idx])][cust_idx] = int(current_algo.predict(target_X[cust_idx]))\n",
    "                self.agg_errorFrame.loc[[idx], 'AE'] += int(abs(target_y[cust_idx] - int(current_algo.predict(target_X[cust_idx]))))\n",
    "            self.agg_errorFrame.loc[[idx], 'MAE'] = self.agg_errorFrame['AE'][idx] / len(self.testFrame)\n",
    "\n",
    "\n",
    "class Customer:\n",
    "    def __init__(self, id, data):\n",
    "        self.id = id\n",
    "        self.data = data\n",
    "        columns = ['regression approach', 'RMSQE', 'AE', 'MAE']\n",
    "        self.errorFrame = pd.DataFrame(columns=columns)\n",
    "        self.init_trainsize = int(len(self.data) * .8)\n",
    "\n",
    "    def formatData(self):\n",
    "        # sort by invoicetodt to make sure there is proper temporal ordering\n",
    "        self.data = self.data.sort_values(by='invoicetodt')\n",
    "\n",
    "        # add tavg_intervalSum squared column -- to more easily capture nonlinear effects\n",
    "        self.data['tavg_intervalSum_sq']  = self.data['tavg_intervalSum']*self.data['tavg_intervalSum']\n",
    "\n",
    "        # add avg_kwh column\n",
    "        self.data['avg_kwh'] = self.data['kwh'].sum() / len(self.data)\n",
    "\n",
    "        # Shave off time intervals after February 25th, 2017\n",
    "        # We do not currently have temperature data after this point\n",
    "        col = 'invoicetodt'\n",
    "        self.data = shaveData(self.data, col, pd.Timestamp(datetime(2017, 2, 25)))\n",
    "        self.data = self.data.reset_index(drop=True)\n",
    "\n",
    "        try:\n",
    "            # add temporal information for models to use\n",
    "            self.data = addTemporalValues(self.data)\n",
    "        except KeyError:\n",
    "            print(\"in formatting data, could not add temporal information to customer ID: \" + str(self.id))\n",
    "            raise ValueError(\"Temporal information formatting exception\")\n",
    "\n",
    "        # add avg_kwh_for_current_month column\n",
    "        self.data['avg_kwh_for_cust_for_current_month'] = self.data['avg_kwh'] # need to initialize with something\n",
    "        for idx in self.data.index:\n",
    "            m = (self.data['month'][idx])\n",
    "            self.data['avg_kwh_for_cust_for_current_month'][idx] = self.data[self.data['month'] == m]['kwh'].sum() \\\n",
    "                                                                   / len(self.data[self.data['month'] == m]['kwh'])\n",
    "\n",
    "        try:\n",
    "            # add one-period time lag\n",
    "            self.data['prev_pd_kwh'] = list(map(lambda idx: self.data['kwh'][max(idx - 1, 0)], self.data.index))\n",
    "            # add two-period time lag\n",
    "            self.data['prev_prev_pd_kwh'] = list(map(lambda idx: self.data['kwh'][max(idx - 2, 0)], self.data.index))\n",
    "            # Shave off first two values, because of the time lag\n",
    "            self.data = self.data[2:]\n",
    "        except KeyError:\n",
    "            print(\"in formatting data, could not add time lags to customer ID: \" + str(self.id))\n",
    "            raise ValueError(\"Time lag formatting exception\")\n",
    "\n",
    "        # add to data which contains customer ID for each instance\n",
    "        self.data['iethicalid'] = self.id\n",
    "        self.createEval()\n",
    "\n",
    "    def createEval(self):\n",
    "        # Separate last row from rest of data - this will be used for prediction evaluation\n",
    "        self.eval = self.data[len(self.data) - 1:]\n",
    "        self.non_eval = self.data[0: len(self.data) - 1]\n",
    "\n",
    "\n",
    "\n",
    "    def displayTempVsUsagePlots(self):\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(self.data['invoicetodt'], self.data['kwh'], 'ro')\n",
    "        plt.plot(self.data['invoicetodt'], self.data['tavg_intervalSum'], 'ro', color='green', )\n",
    "        plt.title('Temperature and kWH values over time')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(self.data['invoicetodt'], self.data['kwh'])\n",
    "        plt.plot(self.data['invoicetodt'], self.data['tavg_intervalSum'], color='green', )\n",
    "        plt.title('Temperature and kWH values over time')\n",
    "        plt.show()\n",
    "\n",
    "    def getTrainingSet(self, init_trainsize, date_idx, train_columns, categorical_columns, target_column):\n",
    "        X = self.data.as_matrix(columns=train_columns)\n",
    "        # TODO: Vectorize\n",
    "        for column in categorical_columns:\n",
    "            cat_col = pd.Categorical(self.data[column])\n",
    "            mx_dummies = pd.get_dummies(cat_col)\n",
    "            X = np.hstack((X, mx_dummies))\n",
    "        y = self.data.as_matrix(columns=[target_column])\n",
    "        train_X = X[: init_trainsize + date_idx]\n",
    "        train_y = y[0: init_trainsize + date_idx]\n",
    "        return train_X, train_y\n",
    "\n",
    "    def getTestSet(self, init_trainsize, date_idx, train_columns, categorical_columns):\n",
    "        X = self.data.as_matrix(columns=train_columns)\n",
    "        # TODO: Vectorize\n",
    "        for column in categorical_columns:\n",
    "            cat_col = pd.Categorical(self.data[column])\n",
    "            mx_dummies = pd.get_dummies(cat_col)\n",
    "            X = np.hstack((X, mx_dummies))\n",
    "        oos_X = X[init_trainsize+date_idx]\n",
    "        return oos_X\n",
    "\n",
    "    def setInitialVals(self, algorithms):\n",
    "        self.data = self.data.reset_index()\n",
    "        all_dates = self.data['invoicetodt']\n",
    "        # Manually resetting the init_trainsize because it messes up for an unknown reason...\n",
    "        self.init_trainsize = int(len(self.data) * .8)\n",
    "        self.init_oos_dates = all_dates[self.init_trainsize:, ]\n",
    "        self.init_oos_dates = self.init_oos_dates.reset_index()\n",
    "\n",
    "        # TODO: Vectorize!??\n",
    "        for idx in algorithms.index:\n",
    "            self.data['predicted_kwh_' + str(algorithms['name'][idx])] = None\n",
    "            self.errorFrame.loc[idx] = ['predicted_kwh_' + str(algorithms['name'][idx]), 0, 0, 0]\n",
    "\n",
    "    def forecastOn(self, date_idx, train_columns, categorical_columns, target_column, algorithms):\n",
    "        train_X, train_y = self.getTrainingSet(self.init_trainsize, date_idx, train_columns, categorical_columns, target_column)\n",
    "        target_X = self.getTestSet(self.init_trainsize, date_idx, train_columns, categorical_columns)\n",
    "        target_y = self.data['kwh'][self.init_trainsize + date_idx]\n",
    "\n",
    "\n",
    "        algorithms['fitted_model'] = algorithms['algorithm']\n",
    "        # TODO: Vectorize\n",
    "        for idx in algorithms.index:\n",
    "            algorithms['fitted_model'][idx] = algorithms['algorithm'][idx].fit(train_X, train_y)\n",
    "            predicted_y = int(algorithms['fitted_model'][idx].predict(target_X))\n",
    "            self.data['predicted_kwh_' + str(algorithms['name'][idx])][self.init_trainsize + date_idx] = predicted_y\n",
    "            error = int(abs(target_y - predicted_y))\n",
    "            self.errorFrame.loc[[idx], 'AE'] += error\n",
    "\n",
    "    def runModels(self, train_columns, categorical_columns, target_column, algorithms):\n",
    "        self.setInitialVals(algorithms)\n",
    "        # TODO: Vectorize!\n",
    "        for date_idx in self.init_oos_dates.index:\n",
    "            try:\n",
    "                self.forecastOn(date_idx, train_columns, categorical_columns, target_column, algorithms)\n",
    "            except ValueError:\n",
    "                print('self.init_oos_dates: ')\n",
    "                print(self.init_oos_dates)\n",
    "                raise ValueError('ValueError caught while trying to forecast on customer: ' + str(self.id) + 'for date_idx ' + str(date_idx))\n",
    "        for idx in algorithms.index:\n",
    "            try:\n",
    "                self.errorFrame.loc[[idx], 'MAE'] = self.errorFrame['AE'][idx] / len(self.init_oos_dates)\n",
    "            except ZeroDivisionError:\n",
    "                print('self.init_oos_dates: ')\n",
    "                print(self.init_oos_dates)\n",
    "                raise ValueError(\"ZeroDivisionError caught while running \" + algorithms['name'][idx] + 'on customer: ' + str(self.id))\n",
    "        self.errorFrame = self.errorFrame.sort_values(by='AE')\n",
    "        self.errorFrame = self.errorFrame.reset_index(drop=True)\n",
    "\n",
    "    def displayBestFit(self):\n",
    "        plt.figure(figsize=(15, 4))\n",
    "        plt.plot(self.data['invoicetodt'], self.data['kwh'], label='actual usage')\n",
    "        plt.plot(self.data['invoicetodt'],\n",
    "                 self.data[(self.errorFrame['regression approach'][0])],\n",
    "                 color='green',\n",
    "                 label=(self.errorFrame['regression approach'][0]))\n",
    "        plt.legend(loc='best')\n",
    "        plt.title('Customer ' + str(self.id) + ': Best fit')\n",
    "        plt.show()\n",
    "\n",
    "    def displayWorstFit(self):\n",
    "        plt.figure(figsize=(15, 4))\n",
    "        plt.plot(self.data['invoicetodt'], self.data['kwh'], label='actual usage')\n",
    "        plt.plot(self.data['invoicetodt'],\n",
    "                 self.data[(self.errorFrame['regression approach'][len(self.errorFrame) - 1])],\n",
    "                 color='red', label=(self.errorFrame['regression approach'][len(self.errorFrame) - 1]))\n",
    "        plt.legend(loc='best')\n",
    "        plt.title('Customer ' + str(self.id) + ': Worst fit')\n",
    "        plt.show()\n",
    "\n",
    "    def displayConclusions(self, algorithms):\n",
    "        # Plot the algorithm results\n",
    "        plt.figure(figsize=(15, 4))\n",
    "        plt.plot(self.data['invoicetodt'], self.data['kwh'], label='actual usage')\n",
    "        plt.plot(self.data['invoicetodt'], self.data['tavg_intervalSum'], color='green',\n",
    "                 label='temperature')\n",
    "        # TODO: Assign a color for each algorithm!!!! AND VECTORIZE!\n",
    "        for idx in algorithms.index:\n",
    "            plt.plot(self.data['invoicetodt'],\n",
    "                     self.data['predicted_kwh_' + str(algorithms['name'][idx])],\n",
    "                     color='red',\n",
    "                     label='predicted usage ' + str(algorithms['name'][idx]))\n",
    "        plt.legend(loc='best')\n",
    "        plt.title('Customer ' + str(self.id) + ': Temperature, kWH, and fitted values over entire time period')\n",
    "        plt.show()\n",
    "\n",
    "        self.displayBestFit()\n",
    "        self.displayWorstFit()\n",
    "\n",
    "    def displaySpecificAlgorithm(self, specified_algorithm_string):\n",
    "        # Plot the algorithm results\n",
    "        plt.figure(figsize=(15, 4))\n",
    "        plt.plot(self.data['invoicetodt'], self.data['kwh'], label='actual usage')\n",
    "        plt.plot(self.data['invoicetodt'], self.data['tavg_intervalSum'], color='green',\n",
    "                 label='temperature')\n",
    "        plt.plot(self.data['invoicetodt'], self.data['predicted_kwh_' + specified_algorithm_string], color='black',\n",
    "                 alpha=0.9, label='predicted usage rf')\n",
    "        plt.legend(loc='best')\n",
    "        plt.title('Customer ' + str(self.id) + ': Temperature, kWH, and fitted values over entire time period')\n",
    "        plt.show()\n",
    "\n",
    "    def getMaximum(self, column):\n",
    "        return self.data[column].max()\n",
    "\n",
    "    def getMinimum(self, column):\n",
    "        return self.data[column].min()\n",
    "\n",
    "    def getValueAtMax(self, column_max, column_target):\n",
    "        d = self.data.sort_values(by=column_max, ascending=False)\n",
    "        return d.reset_index()[column_target][0]\n",
    "\n",
    "    def getValueAtMin(self, column_min, column_target):\n",
    "        d = self.data.sort_values(by=column_min, ascending=True)\n",
    "        return d.reset_index()[column_target][0]\n",
    "\n",
    "\n",
    "class TempComparisonTest:\n",
    "    def __init__(self, cust_count):\n",
    "        self.iter = 0\n",
    "        print('Querying database...')\n",
    "        self.cust_database = queryDatabase()\n",
    "        self.cust_slice = self.cust_database.selectRandomHardSlice(cust_count)\n",
    "        self.cust_slice_minus_temp = self.cust_slice.copy()\n",
    "\n",
    "        my_algorithms_table = pd.DataFrame(columns=['name', 'algorithm'])\n",
    "        my_algorithms_table['name'] = ['rf']\n",
    "        my_algorithms_table['algorithm'] = [RandomForestRegressor(n_estimators=150, min_samples_split=2)]\n",
    "        my_train_columns = ['tavg_intervalSum', 'prev_pd_kwh', 'prev_prev_pd_kwh', 'days_passed']\n",
    "        my_categorical_columns = ['month']\n",
    "        my_interaction_columns = [('month', 'iethicalid', 'categorical', 'categorical')]\n",
    "\n",
    "        self.cust_slice.runModels(my_train_columns, my_categorical_columns, 'kwh', my_algorithms_table)\n",
    "\n",
    "        my_train_columns_minus_temp = ['prev_pd_kwh', 'prev_prev_pd_kwh', 'days_passed']\n",
    "        self.cust_slice_minus_temp.runModels(my_train_columns_minus_temp, my_categorical_columns, 'kwh', my_algorithms_table)\n",
    "\n",
    "    def error_frames(self):\n",
    "        print('RF MAE with Temp: ' + str(self.cust_slice.grand_errorFrame['MAE'][0]))\n",
    "        print('RF MAE without temp: ' + str(self.cust_slice_minus_temp.grand_errorFrame['MAE'][0]))\n",
    "\n",
    "    def avg_kwh(self):\n",
    "        print('Average kwh used: ' + str(self.cust_slice.getSummaryStats('kwh')))\n",
    "\n",
    "    def resetIter(self):\n",
    "        self.iter = 0\n",
    "\n",
    "    def iterNext(self):\n",
    "        if self.iter + 1 < len(self.cust_slice.listSufficient):\n",
    "            self.iter += 1\n",
    "        else:\n",
    "            print('Resetting iter, reached end of list')\n",
    "            self.resetIter()\n",
    "\n",
    "    def compareAndNext(self):\n",
    "        self.cust_slice.listSufficient[self.iter].displaySpecificAlgorithm('rf')\n",
    "        self.cust_slice_minus_temp.listSufficient[self.iter].displaySpecificAlgorithm('rf')\n",
    "        self.iterNext()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T12:48:44.156330Z",
     "start_time": "2017-06-21T12:47:42.067287Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cust_database = queryDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T12:53:12.624321Z",
     "start_time": "2017-06-21T12:51:20.809343Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting slice by IDs...\n",
      "Percent completed:  0.0%\n",
      "Customer selected: 130798\n",
      "Percent completed:  1.0%\n",
      "Customer selected: 39680\n",
      "Percent completed:  2.0%\n",
      "Customer selected: 118757\n",
      "Percent completed:  3.0%\n",
      "Customer discarded, insufficient data: 145892\n",
      "Percent completed:  4.0%\n",
      "Customer discarded, insufficient data: 275515\n",
      "Percent completed:  5.0%\n",
      "Customer selected: 99911\n",
      "Percent completed:  6.0%\n",
      "Customer discarded, insufficient data: 49702\n",
      "Percent completed:  7.000000000000001%\n",
      "Customer discarded, insufficient data: 75062\n",
      "Percent completed:  8.0%\n",
      "Customer selected: 228929\n",
      "Percent completed:  9.0%\n",
      "Customer selected: 20010\n",
      "Percent completed:  10.0%\n",
      "Customer discarded, insufficient data: 137651\n",
      "Percent completed:  11.0%\n",
      "Customer discarded, insufficient data: 229675\n",
      "Percent completed:  12.0%\n",
      "Customer selected: 62402\n",
      "Percent completed:  13.0%\n",
      "Customer selected: 114467\n",
      "Percent completed:  14.000000000000002%\n",
      "Customer discarded, insufficient data: 179377\n",
      "Percent completed:  15.0%\n",
      "Customer discarded, insufficient data: 147437\n",
      "Percent completed:  16.0%\n",
      "Customer discarded, insufficient data: 238539\n",
      "Percent completed:  17.0%\n",
      "Customer selected: 20204\n",
      "Percent completed:  18.0%\n",
      "Customer discarded, insufficient data: 191311\n",
      "Percent completed:  19.0%\n",
      "Customer selected: 154267\n",
      "Percent completed:  20.0%\n",
      "Customer discarded, insufficient data: 278894\n",
      "Percent completed:  21.0%\n",
      "Customer discarded, insufficient data: 265353\n",
      "Percent completed:  22.0%\n",
      "Customer selected: 172026\n",
      "Percent completed:  23.0%\n",
      "Customer discarded, insufficient data: 109478\n",
      "Percent completed:  24.0%\n",
      "Customer selected: 95094\n",
      "Percent completed:  25.0%\n",
      "Customer discarded, insufficient data: 233561\n",
      "Percent completed:  26.0%\n",
      "Customer selected: 213536\n",
      "Percent completed:  27.0%\n",
      "Customer selected: 170262\n",
      "Percent completed:  28.000000000000004%\n",
      "Customer selected: 191763\n",
      "Percent completed:  28.999999999999996%\n",
      "Customer selected: 219211\n",
      "Percent completed:  30.0%\n",
      "Customer selected: 82603\n",
      "Percent completed:  31.0%\n",
      "Customer discarded, insufficient data: 277613\n",
      "Percent completed:  32.0%\n",
      "Customer discarded, insufficient data: 265465\n",
      "Percent completed:  33.0%\n",
      "Customer discarded, insufficient data: 61717\n",
      "Percent completed:  34.0%\n",
      "Customer discarded, insufficient data: 168544\n",
      "Percent completed:  35.0%\n",
      "Customer selected: 150306\n",
      "Percent completed:  36.0%\n",
      "Customer selected: 37976\n",
      "Percent completed:  37.0%\n",
      "Customer discarded, insufficient data: 57147\n",
      "Percent completed:  38.0%\n",
      "Customer selected: 124438\n",
      "Percent completed:  39.0%\n",
      "Customer selected: 128852\n",
      "Percent completed:  40.0%\n",
      "Customer selected: 2971\n",
      "Percent completed:  41.0%\n",
      "Customer discarded, insufficient data: 123126\n",
      "Percent completed:  42.0%\n",
      "Customer discarded, insufficient data: 249899\n",
      "Percent completed:  43.0%\n",
      "Customer selected: 202997\n",
      "Percent completed:  44.0%\n",
      "Customer discarded, insufficient data: 249210\n",
      "Percent completed:  45.0%\n",
      "Customer discarded, insufficient data: 195436\n",
      "Percent completed:  46.0%\n",
      "Customer selected: 210166\n",
      "Percent completed:  47.0%\n",
      "Customer selected: 97409\n",
      "Percent completed:  48.0%\n",
      "Customer selected: 164808\n",
      "Percent completed:  49.0%\n",
      "Customer selected: 218787\n",
      "Percent completed:  50.0%\n",
      "Customer selected: 200575\n",
      "Percent completed:  51.0%\n",
      "Customer selected: 113246\n",
      "Percent completed:  52.0%\n",
      "Customer discarded, insufficient data: 204147\n",
      "Percent completed:  53.0%\n",
      "Customer selected: 130552\n",
      "Percent completed:  54.0%\n",
      "Customer selected: 27510\n",
      "Percent completed:  55.00000000000001%\n",
      "Customer selected: 96777\n",
      "Percent completed:  56.00000000000001%\n",
      "Customer discarded, insufficient data: 265751\n",
      "Percent completed:  56.99999999999999%\n",
      "Customer selected: 76803\n",
      "Percent completed:  57.99999999999999%\n",
      "Customer selected: 31267\n",
      "Percent completed:  59.0%\n",
      "Customer selected: 116932\n",
      "Percent completed:  60.0%\n",
      "Customer discarded, insufficient data: 271727\n",
      "Percent completed:  61.0%\n",
      "Customer selected: 136925\n",
      "Percent completed:  62.0%\n",
      "Customer discarded, insufficient data: 18635\n",
      "Percent completed:  63.0%\n",
      "Customer selected: 195349\n",
      "Percent completed:  64.0%\n",
      "Customer discarded, insufficient data: 171639\n",
      "Percent completed:  65.0%\n",
      "Customer selected: 140298\n",
      "Percent completed:  66.0%\n",
      "Customer selected: 126584\n",
      "Percent completed:  67.0%\n",
      "Customer discarded, insufficient data: 88975\n",
      "Percent completed:  68.0%\n",
      "Customer discarded, insufficient data: 249813\n",
      "Percent completed:  69.0%\n",
      "Customer discarded, insufficient data: 213272\n",
      "Percent completed:  70.0%\n",
      "Customer selected: 154870\n",
      "Percent completed:  71.0%\n",
      "Customer discarded, insufficient data: 170131\n",
      "Percent completed:  72.0%\n",
      "Customer selected: 83282\n",
      "Percent completed:  73.0%\n",
      "Customer discarded, insufficient data: 273776\n",
      "Percent completed:  74.0%\n",
      "Customer discarded, insufficient data: 31897\n",
      "Percent completed:  75.0%\n",
      "Customer selected: 184190\n",
      "Percent completed:  76.0%\n",
      "Customer selected: 147451\n",
      "Percent completed:  77.0%\n",
      "Customer discarded, insufficient data: 144276\n",
      "Percent completed:  78.0%\n",
      "Customer discarded, insufficient data: 935\n",
      "Percent completed:  79.0%\n",
      "Customer selected: 5511\n",
      "Percent completed:  80.0%\n",
      "Customer discarded, insufficient data: 13597\n",
      "Percent completed:  81.0%\n",
      "Customer discarded, insufficient data: 199853\n",
      "Percent completed:  82.0%\n",
      "Customer discarded, insufficient data: 88296\n",
      "Percent completed:  83.0%\n",
      "Customer selected: 182269\n",
      "Percent completed:  84.0%\n",
      "Customer selected: 124998\n",
      "Percent completed:  85.0%\n",
      "Customer selected: 27053\n",
      "Percent completed:  86.0%\n",
      "Customer discarded, insufficient data: 262637\n",
      "Percent completed:  87.0%\n",
      "Customer selected: 219736\n",
      "Percent completed:  88.0%\n",
      "Customer discarded, insufficient data: 73700\n",
      "Percent completed:  89.0%\n",
      "Customer discarded, insufficient data: 213510\n",
      "Percent completed:  90.0%\n",
      "Customer selected: 1647\n",
      "Percent completed:  91.0%\n",
      "Customer selected: 67161\n",
      "Percent completed:  92.0%\n",
      "Customer selected: 132359\n",
      "Percent completed:  93.0%\n",
      "Customer discarded, insufficient data: 179089\n",
      "Percent completed:  94.0%\n",
      "Customer discarded, insufficient data: 13445\n",
      "Percent completed:  95.0%\n",
      "Customer selected: 13422\n",
      "Percent completed:  96.0%\n",
      "Customer selected: 45972\n",
      "Percent completed:  97.0%\n",
      "Customer selected: 188450\n",
      "Percent completed:  98.0%\n",
      "Customer discarded, insufficient data: 95690\n",
      "Percent completed:  99.0%\n",
      "Customer selected: 96315\n",
      "selectSliceByIDs terminated successfully\n",
      "Processed customers: 55\n",
      "Discarded customers: 45\n",
      "Selecting slice by IDs...\n",
      "Percent completed:  0.0%\n",
      "Customer selected: 158348\n",
      "Percent completed:  2.2222222222222223%\n",
      "Customer discarded, insufficient data: 229096\n",
      "Percent completed:  4.444444444444445%\n",
      "Customer discarded, insufficient data: 133587\n",
      "Percent completed:  6.666666666666667%\n",
      "Customer selected: 194108\n",
      "Percent completed:  8.88888888888889%\n",
      "Customer discarded, insufficient data: 186907\n",
      "Percent completed:  11.11111111111111%\n",
      "Customer discarded, insufficient data: 125268\n",
      "Percent completed:  13.333333333333334%\n",
      "Customer selected: 70556\n",
      "Percent completed:  15.555555555555555%\n",
      "Customer selected: 161984\n",
      "Percent completed:  17.77777777777778%\n",
      "Customer selected: 66159\n",
      "Percent completed:  20.0%\n",
      "Customer discarded, insufficient data: 88034\n",
      "Percent completed:  22.22222222222222%\n",
      "Customer selected: 228230\n",
      "Percent completed:  24.444444444444443%\n",
      "Customer selected: 133915\n",
      "Percent completed:  26.666666666666668%\n",
      "Customer discarded, insufficient data: 264435\n",
      "Percent completed:  28.888888888888886%\n",
      "Customer discarded, insufficient data: 219305\n",
      "Percent completed:  31.11111111111111%\n",
      "Customer discarded, insufficient data: 108675\n",
      "Percent completed:  33.33333333333333%\n",
      "Customer discarded, insufficient data: 73680\n",
      "Percent completed:  35.55555555555556%\n",
      "Customer discarded, insufficient data: 253681\n",
      "Percent completed:  37.77777777777778%\n",
      "Customer selected: 152803\n",
      "Percent completed:  40.0%\n",
      "Customer discarded, insufficient data: 187346\n",
      "Percent completed:  42.22222222222222%\n",
      "Customer selected: 34488\n",
      "Percent completed:  44.44444444444444%\n",
      "Customer discarded, insufficient data: 46909\n",
      "Percent completed:  46.666666666666664%\n",
      "Customer discarded, insufficient data: 12133\n",
      "Percent completed:  48.888888888888886%\n",
      "Customer discarded, insufficient data: 159400\n",
      "Percent completed:  51.11111111111111%\n",
      "Customer selected: 148893\n",
      "Percent completed:  53.333333333333336%\n",
      "Customer selected: 38991\n",
      "Percent completed:  55.55555555555556%\n",
      "Customer selected: 65762\n",
      "Percent completed:  57.77777777777777%\n",
      "Customer discarded, insufficient data: 259591\n",
      "Percent completed:  60.0%\n",
      "Customer selected: 100528\n",
      "Percent completed:  62.22222222222222%\n",
      "Customer discarded, insufficient data: 150322\n",
      "Percent completed:  64.44444444444444%\n",
      "Customer selected: 62489\n",
      "Percent completed:  66.66666666666666%\n",
      "Customer selected: 196713\n",
      "Percent completed:  68.88888888888889%\n",
      "Customer selected: 199889\n",
      "Percent completed:  71.11111111111111%\n",
      "Customer selected: 94817\n",
      "Percent completed:  73.33333333333333%\n",
      "Customer discarded, insufficient data: 157208\n",
      "Percent completed:  75.55555555555556%\n",
      "Customer discarded, insufficient data: 196402\n",
      "Percent completed:  77.77777777777779%\n",
      "Customer selected: 160507\n",
      "Percent completed:  80.0%\n",
      "Customer discarded, insufficient data: 138690\n",
      "Percent completed:  82.22222222222221%\n",
      "Customer selected: 14886\n",
      "Percent completed:  84.44444444444444%\n",
      "Customer selected: 113726\n",
      "Percent completed:  86.66666666666667%\n",
      "Customer discarded, insufficient data: 202325\n",
      "Percent completed:  88.88888888888889%\n",
      "Customer selected: 11137\n",
      "Percent completed:  91.11111111111111%\n",
      "Customer discarded, insufficient data: 262714\n",
      "Percent completed:  93.33333333333333%\n",
      "Customer discarded, insufficient data: 271548\n",
      "Percent completed:  95.55555555555556%\n",
      "Customer selected: 102451\n",
      "Percent completed:  97.77777777777777%\n",
      "Customer selected: 149489\n",
      "selectSliceByIDs terminated successfully\n",
      "Processed customers: 23\n",
      "Discarded customers: 22\n",
      "Selecting slice by IDs...\n",
      "Percent completed:  0.0%\n",
      "Customer selected: 155346\n",
      "Percent completed:  4.545454545454546%\n",
      "Customer selected: 63084\n",
      "Percent completed:  9.090909090909092%\n",
      "Customer discarded, insufficient data: 236844\n",
      "Percent completed:  13.636363636363635%\n",
      "Customer selected: 96082\n",
      "Percent completed:  18.181818181818183%\n",
      "Customer discarded, insufficient data: 229386\n",
      "Percent completed:  22.727272727272727%\n",
      "Customer selected: 187214\n",
      "Percent completed:  27.27272727272727%\n",
      "Customer selected: 178917\n",
      "Percent completed:  31.818181818181817%\n",
      "Customer discarded, insufficient data: 110075\n",
      "Percent completed:  36.36363636363637%\n",
      "Customer discarded, insufficient data: 251673\n",
      "Percent completed:  40.909090909090914%\n",
      "Customer discarded, insufficient data: 265718\n",
      "Percent completed:  45.45454545454545%\n",
      "Customer selected: 222405\n",
      "Percent completed:  50.0%\n",
      "Customer selected: 89243\n",
      "Percent completed:  54.54545454545454%\n",
      "Customer discarded, insufficient data: 169337\n",
      "Percent completed:  59.09090909090909%\n",
      "Customer discarded, insufficient data: 268686\n",
      "Percent completed:  63.63636363636363%\n",
      "Customer selected: 229502\n",
      "Percent completed:  68.18181818181817%\n",
      "Customer discarded, insufficient data: 189289\n",
      "Percent completed:  72.72727272727273%\n",
      "Customer selected: 176394\n",
      "Percent completed:  77.27272727272727%\n",
      "Customer discarded, insufficient data: 68117\n",
      "Percent completed:  81.81818181818183%\n",
      "Customer discarded, insufficient data: 196102\n",
      "Percent completed:  86.36363636363636%\n",
      "Customer selected: 180855\n",
      "Percent completed:  90.9090909090909%\n",
      "Customer selected: 150129\n",
      "Percent completed:  95.45454545454545%\n",
      "Customer selected: 161492\n",
      "selectSliceByIDs terminated successfully\n",
      "Processed customers: 12\n",
      "Discarded customers: 10\n",
      "Selecting slice by IDs...\n",
      "Percent completed:  0.0%\n",
      "Customer discarded, insufficient data: 189792\n",
      "Percent completed:  10.0%\n",
      "Customer discarded, insufficient data: 262269\n",
      "Percent completed:  20.0%\n",
      "Customer selected: 226980\n",
      "Percent completed:  30.0%\n",
      "Customer discarded, insufficient data: 256654\n",
      "Percent completed:  40.0%\n",
      "Customer discarded, insufficient data: 263538\n",
      "Percent completed:  50.0%\n",
      "Customer selected: 117146\n",
      "Percent completed:  60.0%\n",
      "Customer discarded, insufficient data: 6015\n",
      "Percent completed:  70.0%\n",
      "Customer selected: 177669\n",
      "Percent completed:  80.0%\n",
      "Customer discarded, insufficient data: 196939\n",
      "Percent completed:  90.0%\n",
      "Customer discarded, insufficient data: 133877\n",
      "selectSliceByIDs terminated successfully\n",
      "Processed customers: 3\n",
      "Discarded customers: 7\n",
      "Selecting slice by IDs...\n",
      "Percent completed:  0.0%\n",
      "Customer selected: 173867\n",
      "Percent completed:  14.285714285714285%\n",
      "Customer selected: 84753\n",
      "Percent completed:  28.57142857142857%\n",
      "Customer selected: 219809\n",
      "Percent completed:  42.857142857142854%\n",
      "Customer discarded, insufficient data: 95387\n",
      "Percent completed:  57.14285714285714%\n",
      "Customer discarded, insufficient data: 3064\n",
      "Percent completed:  71.42857142857143%\n",
      "Customer selected: 181220\n",
      "Percent completed:  85.71428571428571%\n",
      "Customer selected: 175868\n",
      "selectSliceByIDs terminated successfully\n",
      "Processed customers: 5\n",
      "Discarded customers: 2\n",
      "Selecting slice by IDs...\n",
      "Percent completed:  0.0%\n",
      "Customer selected: 128268\n",
      "Percent completed:  50.0%\n",
      "Customer selected: 7099\n",
      "selectSliceByIDs terminated successfully\n",
      "Processed customers: 2\n",
      "Discarded customers: 0\n"
     ]
    }
   ],
   "source": [
    "cust_slice = cust_database.selectRandomHardSlice(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T12:53:12.651640Z",
     "start_time": "2017-06-21T12:53:12.636320Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_algorithms_table = pd.DataFrame(columns=['name', 'algorithm'])\n",
    "my_algorithms_table['name'] = ['ols']\n",
    "my_algorithms_table['algorithm'] = [linear_model.LinearRegression(fit_intercept=True)]\n",
    "my_train_columns = ['tavg_intervalSum', 'tavg_intervalSum_sq', 'prev_pd_kwh', 'prev_prev_pd_kwh', 'days_passed', 'iethicalid', 'avg_kwh', 'avg_kwh_for_cust_for_current_month']\n",
    "my_categorical_columns = ['month', 'iethicalid']\n",
    "my_interaction_columns = [('month', 'tavg_intervalSum', 'categorical', 'numerical'), ('iethicalid', 'tavg_intervalSum', 'categorical', 'numerical'), ('iethicalid', 'tavg_intervalSum', 'categorical', 'numerical')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T12:53:17.393763Z",
     "start_time": "2017-06-21T12:53:12.686513Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cust_slice.run_aggregate_models(my_train_columns, my_categorical_columns, my_interaction_columns, 'kwh', my_algorithms_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T12:54:20.667596Z",
     "start_time": "2017-06-21T12:54:20.650909Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regression approach</th>\n",
       "      <th>RMSQE</th>\n",
       "      <th>AE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>predicted_kwh_ols</td>\n",
       "      <td>0</td>\n",
       "      <td>11522</td>\n",
       "      <td>115.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  regression approach RMSQE     AE     MAE\n",
       "0   predicted_kwh_ols     0  11522  115.22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_slice.agg_errorFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T12:54:24.725112Z",
     "start_time": "2017-06-21T12:54:24.709115Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.87043344e-01,   7.18977853e-05,   1.33924847e-01,\n",
       "          2.56231139e-02,   2.26962277e-02,  -3.05989822e-04,\n",
       "         -6.89791866e-02,   9.16961897e-01,   2.50878016e+01,\n",
       "          1.03609083e+02,   1.38577916e+02,   1.62064877e+02,\n",
       "         -1.81834298e+01,  -1.34876491e+02,   1.45641909e+01,\n",
       "         -3.98684895e+01,  -1.35719002e+02,  -1.04324007e+02,\n",
       "         -6.07614880e+01,   4.98290394e+01,   4.59756020e+02,\n",
       "          3.80655277e+02,   2.30404044e+02,   2.63936857e+02,\n",
       "         -1.18221604e+02,  -9.83785314e+01,  -1.32789576e+02,\n",
       "         -8.01468726e+01,   3.15792490e+00,  -1.70286761e+01,\n",
       "         -3.05987943e+01,   7.08045037e+00,   2.85493177e+00,\n",
       "         -7.60151941e+01,  -2.45407913e+02,  -9.46005419e+01,\n",
       "         -4.49127004e+01,  -1.43625411e+01,  -9.81106711e+01,\n",
       "          8.64384914e+01,  -2.94101008e+01,  -1.54140847e+01,\n",
       "          3.53495867e+01,   3.61857706e+02,  -1.50752633e+02,\n",
       "         -9.00396312e+01,  -4.71830552e+01,   2.72616880e+02,\n",
       "         -9.00715818e+01,  -1.60178504e+02,  -9.27306478e+01,\n",
       "         -7.00920828e+02,  -5.21433899e+01,  -4.36296465e+01,\n",
       "          1.54228433e+02,   1.38272075e+01,   6.65903825e+01,\n",
       "         -1.03347074e+02,   1.65055256e+01,  -1.07359936e+02,\n",
       "          5.59086886e+01,  -8.26274410e+01,  -2.11359350e+01,\n",
       "          8.53193937e+00,  -8.95605709e+01,   1.88253805e+01,\n",
       "          1.00643925e+02,   1.00267689e+01,   5.64048719e+01,\n",
       "         -2.86520461e+00,  -3.10318271e+01,  -1.02730455e+01,\n",
       "         -6.60783088e+01,  -1.85689621e+00,  -4.62509207e+01,\n",
       "         -2.83606459e+02,   3.19990735e+01,  -1.28393462e+01,\n",
       "         -2.52195903e+01,  -3.70941093e+02,  -1.75537885e+01,\n",
       "          1.79292858e+01,   3.81772186e+01,   4.58537606e+01,\n",
       "         -1.26382072e+01,  -3.63509350e+01,  -1.46975483e+01,\n",
       "         -1.02284969e+01,   2.06274274e+01,   7.96850513e+01,\n",
       "         -2.85586803e+01,   2.54903849e+01,   1.94666342e+02,\n",
       "         -4.03399338e+01,   1.23276454e+02,  -1.32082633e+02,\n",
       "          8.95702541e+01,  -1.09706908e+01,  -4.38650995e+01,\n",
       "          5.88332426e+01,   1.20521397e+02,   1.02738508e+02,\n",
       "          1.37707508e+02,   1.01480317e+02,   7.96289568e+00,\n",
       "         -5.47994917e-01,   1.03206978e+02,  -3.42478926e+01,\n",
       "          8.26213520e+01,   9.35407699e+01,   1.27989485e+02,\n",
       "          2.87287498e+01,   1.79630383e+02,   2.91009425e+01,\n",
       "         -1.51024928e+02,  -7.73841050e+01,   4.86928437e-06,\n",
       "          1.64216560e-05,   9.74665881e-06,  -5.84068032e+01,\n",
       "         -3.29830710e-03,  -8.80967313e-02,  -1.19267786e-01,\n",
       "         -9.97330139e-02,   1.51167434e-02,   5.53392870e-02,\n",
       "         -1.92138877e-02,  -6.27870764e-03,   2.48711629e-02,\n",
       "          3.09588659e-02,   3.71769214e-02,  -1.46178680e-02,\n",
       "         -1.09304178e-01,  -9.51438272e-02,  -6.78398091e-02,\n",
       "         -1.36528525e-01,   1.23684743e-02,   1.40257898e-02,\n",
       "          4.12337780e-02,   8.93238739e-04,  -1.81950276e-02,\n",
       "         -4.67659160e-03,  -7.55920740e-03,  -1.67707806e-02,\n",
       "         -2.13580825e-02,   8.97270633e-03,   3.12554347e-02,\n",
       "          1.46236462e-02,  -6.64870469e-03,  -7.50319093e-03,\n",
       "          1.71784310e-02,  -2.84969052e-02,   6.16357413e-03,\n",
       "         -6.65935070e-03,  -1.24967600e-02,  -8.88549181e-02,\n",
       "          3.05331412e-02,   2.45359465e-02,   1.16475360e-02,\n",
       "         -6.44613328e-02,   2.31845163e-02,   5.28340800e-02,\n",
       "          2.70095701e-02,   1.89961151e-01,   5.60766941e-03,\n",
       "          2.70742933e-03,  -4.57209730e-02,  -1.10457811e-02,\n",
       "         -2.57268382e-02,   2.82898949e-02,  -1.17737990e-02,\n",
       "          3.14389842e-02,  -1.60042291e-02,   2.04026686e-02,\n",
       "          5.32467672e-04,  -8.11070225e-03,   1.99209402e-02,\n",
       "         -1.31144645e-02,  -3.02927540e-02,  -7.28580567e-03,\n",
       "         -1.98182010e-02,  -2.33653189e-03,   5.25311063e-03,\n",
       "         -2.65374863e-03,   1.76181950e-02,  -1.84258960e-03,\n",
       "          7.84352600e-03,   6.26708283e-02,  -9.81404318e-03,\n",
       "          4.39757328e-03,   7.94151906e-03,   9.60701758e-02,\n",
       "          4.40564036e-03,  -6.02191293e-03,  -1.23357236e-02,\n",
       "          1.57354869e-02,   2.74938008e-03,   1.53272306e-02,\n",
       "          8.80642621e-03,   1.18508429e-02,  -2.11756187e-03,\n",
       "         -2.19400306e-02,   9.60706679e-03,  -2.95264310e-03,\n",
       "         -5.67746166e-02,   2.41783603e-02,  -4.19965815e-02,\n",
       "          5.84761619e-02,  -2.45635576e-02,   6.04314393e-03,\n",
       "          1.37503607e-02,  -1.44411738e-02,  -3.44608186e-02,\n",
       "         -2.68893403e-02,  -3.83791583e-02,  -3.08375184e-02,\n",
       "          6.38150092e-03,   2.84284052e-03,  -2.62516632e-02,\n",
       "          1.77354819e-02,  -2.02393155e-02,  -2.31948611e-02,\n",
       "         -3.68519188e-02,  -4.01474182e-03,  -5.16719995e-02,\n",
       "         -3.19835998e-03,   6.71251097e-02,   3.16857357e-02,\n",
       "          6.10538437e-03,   2.09539821e-02,   1.17551682e-02,\n",
       "          3.74965046e-02,  -1.09304177e-01,  -9.51438267e-02,\n",
       "         -6.78398081e-02,  -1.36528525e-01,   1.23684751e-02,\n",
       "          1.40257881e-02,   4.12337783e-02,   8.93238702e-04,\n",
       "         -1.81950245e-02,  -4.67659442e-03,  -7.55920413e-03,\n",
       "         -1.67707789e-02,  -2.13580812e-02,   8.97270137e-03,\n",
       "          3.12554340e-02,   1.46236455e-02,  -6.64870913e-03,\n",
       "         -7.50319077e-03,   1.71784305e-02,  -2.84969062e-02,\n",
       "          6.16357337e-03,  -6.65935244e-03,  -1.24967596e-02,\n",
       "         -8.88548835e-02,   3.05331419e-02,   2.45359482e-02,\n",
       "          1.16475363e-02,  -6.44613325e-02,   2.31845163e-02,\n",
       "          5.28340800e-02,   2.70095732e-02,   1.89961151e-01,\n",
       "          5.60766956e-03,   2.70743068e-03,  -4.57209742e-02,\n",
       "         -1.10457809e-02,  -2.57268373e-02,   2.82898952e-02,\n",
       "         -1.17737980e-02,   3.14389833e-02,  -1.60042262e-02,\n",
       "          2.04026686e-02,   5.32467872e-04,  -8.11070185e-03,\n",
       "          1.99209399e-02,  -1.31144645e-02,  -3.02927539e-02,\n",
       "         -7.28580516e-03,  -1.98182003e-02,  -2.33653255e-03,\n",
       "          5.25310943e-03,  -2.65374980e-03,   1.76181954e-02,\n",
       "         -1.84258887e-03,   7.84352531e-03,   6.26708279e-02,\n",
       "         -9.81404662e-03,   4.39757292e-03,   7.94151747e-03,\n",
       "          9.60701738e-02,   4.40564013e-03,  -6.02191254e-03,\n",
       "         -1.23357245e-02,   1.57354877e-02,   2.74938182e-03,\n",
       "          1.53272277e-02,   8.80642773e-03,   1.18508427e-02,\n",
       "         -2.11756134e-03,  -2.19400304e-02,   9.60706708e-03,\n",
       "         -2.95264409e-03,  -5.67746174e-02,   2.41783612e-02,\n",
       "         -4.19965815e-02,   5.84761621e-02,  -2.45635569e-02,\n",
       "          6.04314316e-03,   1.37503602e-02,  -1.44411723e-02,\n",
       "         -3.44608184e-02,  -2.68893407e-02,  -3.83791575e-02,\n",
       "         -3.08375200e-02,   6.38150140e-03,   2.84283860e-03,\n",
       "         -2.62516630e-02,   1.77354787e-02,  -2.02393152e-02,\n",
       "         -2.31948611e-02,  -3.68519183e-02,  -4.01474087e-03,\n",
       "         -5.16719999e-02,  -3.19836144e-03,   6.71251094e-02,\n",
       "          3.16857355e-02,   6.10538435e-03,   2.09539819e-02,\n",
       "          1.17551685e-02,   3.74965035e-02]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_algorithms_table['fitted_model'][0].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T12:56:09.967326Z",
     "start_time": "2017-06-21T12:56:09.835823Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_train_columns = ['tavg_intervalSum', 'prev_pd_kwh', 'prev_prev_pd_kwh', 'days_passed', 'avg_kwh_for_cust_for_current_month']\n",
    "my_categorical_columns = ['month']\n",
    "cust_slice_3 = cust_slice.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T12:56:29.713158Z",
     "start_time": "2017-06-21T12:56:11.340652Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent completed:  1.0%\n",
      "Percent completed:  2.0%\n",
      "Percent completed:  3.0%\n",
      "Percent completed:  4.0%\n",
      "Percent completed:  5.0%\n",
      "Percent completed:  6.0%\n",
      "Percent completed:  7.000000000000001%\n",
      "Percent completed:  8.0%\n",
      "Percent completed:  9.0%\n",
      "Percent completed:  10.0%\n",
      "Percent completed:  11.0%\n",
      "Percent completed:  12.0%\n",
      "Percent completed:  13.0%\n",
      "Percent completed:  14.000000000000002%\n",
      "Percent completed:  15.0%\n",
      "Percent completed:  16.0%\n",
      "Percent completed:  17.0%\n",
      "Percent completed:  18.0%\n",
      "Percent completed:  19.0%\n",
      "Percent completed:  20.0%\n",
      "Percent completed:  21.0%\n",
      "Percent completed:  22.0%\n",
      "Percent completed:  23.0%\n",
      "Percent completed:  24.0%\n",
      "Percent completed:  25.0%\n",
      "Percent completed:  26.0%\n",
      "Percent completed:  27.0%\n",
      "Percent completed:  28.000000000000004%\n",
      "Percent completed:  28.999999999999996%\n",
      "Percent completed:  30.0%\n",
      "Percent completed:  31.0%\n",
      "Percent completed:  32.0%\n",
      "Percent completed:  33.0%\n",
      "Percent completed:  34.0%\n",
      "Percent completed:  35.0%\n",
      "Percent completed:  36.0%\n",
      "Percent completed:  37.0%\n",
      "Percent completed:  38.0%\n",
      "Percent completed:  39.0%\n",
      "Percent completed:  40.0%\n",
      "Percent completed:  41.0%\n",
      "Percent completed:  42.0%\n",
      "Percent completed:  43.0%\n",
      "Percent completed:  44.0%\n",
      "Percent completed:  45.0%\n",
      "Percent completed:  46.0%\n",
      "Percent completed:  47.0%\n",
      "Percent completed:  48.0%\n",
      "Percent completed:  49.0%\n",
      "Percent completed:  50.0%\n",
      "Percent completed:  51.0%\n",
      "Percent completed:  52.0%\n",
      "Percent completed:  53.0%\n",
      "Percent completed:  54.0%\n",
      "Percent completed:  55.00000000000001%\n",
      "Percent completed:  56.00000000000001%\n",
      "Percent completed:  56.99999999999999%\n",
      "Percent completed:  57.99999999999999%\n",
      "Percent completed:  59.0%\n",
      "Percent completed:  60.0%\n",
      "Percent completed:  61.0%\n",
      "Percent completed:  62.0%\n",
      "Percent completed:  63.0%\n",
      "Percent completed:  64.0%\n",
      "Percent completed:  65.0%\n",
      "Percent completed:  66.0%\n",
      "Percent completed:  67.0%\n",
      "Percent completed:  68.0%\n",
      "Percent completed:  69.0%\n",
      "Percent completed:  70.0%\n",
      "Percent completed:  71.0%\n",
      "Percent completed:  72.0%\n",
      "Percent completed:  73.0%\n",
      "Percent completed:  74.0%\n",
      "Percent completed:  75.0%\n",
      "Percent completed:  76.0%\n",
      "Percent completed:  77.0%\n",
      "Percent completed:  78.0%\n",
      "Percent completed:  79.0%\n",
      "Percent completed:  80.0%\n",
      "Percent completed:  81.0%\n",
      "Percent completed:  82.0%\n",
      "Percent completed:  83.0%\n",
      "Percent completed:  84.0%\n",
      "Percent completed:  85.0%\n",
      "Percent completed:  86.0%\n",
      "Percent completed:  87.0%\n",
      "Percent completed:  88.0%\n",
      "Percent completed:  89.0%\n",
      "Percent completed:  90.0%\n",
      "Percent completed:  91.0%\n",
      "Percent completed:  92.0%\n",
      "Percent completed:  93.0%\n",
      "Percent completed:  94.0%\n",
      "Percent completed:  95.0%\n",
      "Percent completed:  96.0%\n",
      "Percent completed:  97.0%\n",
      "Percent completed:  98.0%\n",
      "Percent completed:  99.0%\n",
      "Percent completed:  100.0%\n"
     ]
    }
   ],
   "source": [
    "cust_slice_3.runModels(my_train_columns, my_categorical_columns, 'kwh', my_algorithms_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T12:56:39.883283Z",
     "start_time": "2017-06-21T12:56:39.864452Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regression approach</th>\n",
       "      <th>RMSQE</th>\n",
       "      <th>AE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>predicted_kwh_ols</td>\n",
       "      <td>0</td>\n",
       "      <td>65821</td>\n",
       "      <td>181.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  regression approach RMSQE     AE     MAE\n",
       "0   predicted_kwh_ols     0  65821  181.07"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_slice_3.grand_errorFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T13:02:56.410531Z",
     "start_time": "2017-06-21T13:02:56.381087Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534.33661243588"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_slice.getSummaryStats('kwh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T12:56:43.664187Z",
     "start_time": "2017-06-21T12:56:43.652658Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -2.14782000e+00,  -1.09323015e-02,   1.17940853e-01,\n",
       "          3.10924552e-02,  -3.47404666e-01,   3.18868629e-03,\n",
       "         -3.30650554e-03,   0.00000000e+00,   1.17819254e-04]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_algorithms_table['fitted_model'][0].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T12:58:06.860214Z",
     "start_time": "2017-06-21T12:58:06.848437Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "549.2712915254237"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_slice.allFrame['kwh'].sum()/len(cust_slice.allFrame['kwh'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
